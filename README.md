# spam_filter
Implementation of Naive Bayes classificator to solve task of filtration spam.
Решаем задачу классификации спама с помощью наивного Байеса. Первая проблема, с которой мы столкнулись - непонятно, как превратить текст в признаки, потому что с таким прежде не работали, непонятно, что делать. На помощь приходит TF-IDF-vectorizer, который работает по следующему принципу:
TF (частота термина или term frequency):

$$TF(t, d) = \text{количество вхождений слова t в d}$$

считает сколько слово появляется в данном документе, таким образом, измеряем важность слова в контексте каждого документа.
IDF (Обратная частота документа):
$$IDF(t) = \text{log(\frac{1 + N}{1 + \text{df_{t}(колво в доках)}}$$
считает насколько часто слово появляется в каждом документе и берет обратную от него величину, чтобы понять насколько слово уникально для того, чтобы описывать каждый отдельный документ
TF-IDF:
$$TF-IDF(t, d) = TF(t,d) * IDF(t)$$
Плюсы:
1. Можем хоть как-то пытаться учитывать слова по их важности во всех документах
2. Слова, которые встречаются во всех документах, например, слово *the* на английском, имеют очень низкое значение TF-IDF
Минусы:
1. Непонятно, как нормально оценивать предложения и вообще их склеивать
2. 
