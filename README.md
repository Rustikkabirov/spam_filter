# spam_filter
Implementation of Naive Bayes classificator to solve task of filtration spam.
Решаем задачу классификации спама с помощью наивного Байеса. Первая проблема, с которой мы столкнулись - непонятно, как превратить текст в признаки, потому что с таким прежде не работали, непонятно, что делать. На помощь приходит TF-IDF-vectorizer, который работает по следующему принципу:
TF (частота термина или term frequency):

$$TF(t, d) = \text{количество вхождений слова t в d}$$

считает сколько слово появляется в данном документе, таким образом, измеряем важность слова в контексте каждого документа.
IDF (Обратная частота документа):
считает насколько часто слово появляется в каждом документе и берет обратную от него величину, чтобы понять насколько слово уникально для того, чтобы описывать каждый отдельный документ
TF-IDF:
TF-IDF(t, d) = TF(t,d) * IDF(t)
Плюсы:
1. Можем хоть как-то пытаться учитывать слова по их важности во всех документах
2. Слова, которые встречаются во всех документах, например, слово *the* на английском, имеют очень низкое значение TF-IDF
Минусы:
1. Непонятно, как нормально оценивать предложения и вообще их склеивать
2. Чувствительность к длине документа, поскольку нет нормировки на длину документа в TF, то более длинный документ по закону больших чисел может иметь больше вхождений t в d

## Naive-Bayes

1. Воспользовались предположением о независимости наших признаков, хотя очевидно, что слова в предложении зависимы и нельзя просто напросто говорить о независимости признаков
2. Признаков более тысячи, поэтому отсматривать точность в соответствии с нормальным распределением для каждого признака, для которого мы "набрасывали" равномерное распределение - не представляется возможным, поэтому считаем что все признаки распределены равномерно

#### Выбор метрик
1. У нас очень несбалансированная выборка, один класс больше другого почти в 10 раз
2. Нужно следить за тем, чтобы как можно больше спама попадало в нужную корзину
3. При этом очень важно следить за тем, чтобы как можно меньше не спама попадало в спам
Откуда напрашивается следить за метрикой:
1. Precision/Recall и AUC-RPC (метрика AUC-RPC устойчива к дисбалансу классов)
Где precision = (TP) / (TP + FP) (насколько точно мы угадываем первый класс), а Recall = (TP)/(TP + FN) - (насколько полно мы покрыли первый класс)

### Результаты 
<img width="664" height="615" alt="image" src="https://github.com/user-attachments/assets/bfbbaff8-5b09-4ced-a80c-aef106ed8837" />

Наивный Байес показал довольно хорошие результаты для такой наивной имплементации, поэтому стоит отметить, что модель довольно хорошо решает нашу задачу, а точнее:
1. Модель много лишних писем отправляет в спам (все равно приемлемо т.к значение 0.53 - хорошо)
2. Однако, очень хорошо определяет где спам, а где нет
Поэтому можем сделать вывод, что модель отлично справилась с задачей.

Однако, можем заметить, что линейная модель, а также нейронная сеть справились гораздо лучше с задачей(фотографии ниже соответственно):
<img width="611" height="617" alt="image" src="https://github.com/user-attachments/assets/5a09e484-0005-431a-9896-13d4e2ea8a5b" />
Линейная модель меньше лишних писем отправляет в спам, приэтом ловит меньше спама, но именно потому, что меньше писем в спаме лишних - модель лучше справилась с задачей
<img width="690" height="636" alt="image" src="https://github.com/user-attachments/assets/6f3d7cc8-a86c-4a2f-9e4b-7345767d99c6" />

Ну и по той же причине нейронная сеть справилась лучше обеих моделей, описанных вышею


